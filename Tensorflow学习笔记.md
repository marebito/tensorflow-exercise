### Tensorflow学习笔记
--

基本步骤:
1. (下载)导入数据集
2. 探索数据（预处理数据）
3. 准备数据
4. 配置模型的层
5. 编译模型(compile)
6. 训练模型(fit)
7. 评估模型(evaluate)

* 训练集即模型用于学习的数据，测试集即用于测试的数据。
* 层是神经网络的基本构造块，层从馈送到其中的数据中提取表示结果。
* 损失函数--衡量模型在训练期间的准确率。尽可能的缩小该函数，以“引导”模型朝着正确的方向优化。
* 优化器--根据模型看到的数据机器损失函数更新模型的非那个是。
* 指标 - 用于监控训练和测试步骤。

> 训练神经网络的模型的执行步骤：
1. 将训练数据馈送到模型中。
2. 模型学习将数据(图像)与标签相关联。
3. 让模型对测试集进行预测，验证预测结果是否与test_labels 数组中的标签一致。

* 模型在输入和输出之间有两个中间层（也称为“隐藏”层）。输出（单元、节点或神经元）的数量是相应层的表示法空间的维度。换句话说，该数值表示学习内部表示法时网络所允许的自由度。

* 模型会返回两个值：损失（表示误差的数字，越低越好）和准确率

* 均方误差（MSE）是用于回归问题的常见损失函数（不同于分类问题）。

* 同样，用于回归的评估指标也不同于分类。常见的回归指标是平均绝对误差（MAE）。

* 当输入数据要素具有不同范围的值时，应单独缩放每个要素。

* 如果训练数据不多，则选择隐藏层较少的小型网络，以避免过度拟合。

* 早期停止是防止过度拟合的有用技术。

* 防止发生过拟合的最好解决方案是使用更多训练数据。正则化技术次之。

* 防止过拟合最简单的方法是缩小模型，即减少模型中可学习参数的数量(有层数和每层的单元数决定)。

* 在深度学习中，模型中可学习参数的数量通常称为模型的“容量”。

* 深度学习模型往往善于与训练数据拟合，但真正的挑战是泛化，而非拟合。

* 要找到合适的模型大小，最好先使用相对较少的层和参数，然后开始增加层的大小或添加新的层，直到看到返回的验证损失不断减小为止。

* 卷积提取局部特征，全连接就是把以前的局部特征重新通过权值矩阵组装成完整的图。

* 图像中不同的特征会激活不同的卷积核。

* 池化层（仅指最大池化）起着类似于“合票”的作用，不同特征在对不同的“候选人”有着各自的喜好

* 验证损失越低，表示模型越好。